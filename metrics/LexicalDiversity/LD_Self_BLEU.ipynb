{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self BLEU\n",
    "A high Self-BLEU score indicates that the generated texts are very similar to each other, suggesting low diversity, while a lower Self-BLEU score suggests higher diversity, therefore we report 1 - self Bleu which reverses this for a more intuitive reading. Thus the higher the reporte score the higher the diversity. \n",
    "\n",
    "The weights parameter in sentence_bleu is set to give equal importance to 1-gram, 2-gram, 3-gram, and 4-gram matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def calculate_self_bleu(texts):\n",
    "    \"\"\"\n",
    "    Calculate the Self-BLEU score for a set of texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - texts (list of str): The set of generated texts to be evaluated.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The average Self-BLEU score of the texts.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    # Ensure that inputs are cleaned and non-empty\n",
    "    cleaned_texts = [text.strip() for text in texts if text.strip()]\n",
    "    print(\"Length\", len(cleaned_texts))\n",
    "    \n",
    "    # Check if there are fewer than two valid texts\n",
    "    if len(cleaned_texts) < 2:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    for i, candidate in enumerate(texts):\n",
    "        if not candidate.strip():  # Skip empty candidates\n",
    "            continue\n",
    "        \n",
    "        # Consider all other texts as references for the current candidate text\n",
    "        references = [word_tokenize(texts[j].lower()) for j in range(len(texts)) if i != j and texts[j].strip()]\n",
    "        candidate_tokens = word_tokenize(candidate.lower())\n",
    "        \n",
    "        if not references or not candidate_tokens:  # Skip if no valid data is available\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Calculate the BLEU score for this text against all others\n",
    "            score = sentence_bleu(references, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "            scores.append(score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating BLEU for text index {i}: {e}\")\n",
    "            continue  # Handle possible errors during BLEU calculation\n",
    "    \n",
    "    # Calculate the average score across all texts\n",
    "    average_score = sum(scores) / len(scores) if scores else 0\n",
    "    return average_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"I was in charge of protecting your country from the Dark Side, but I had to do it because my life depended on me not knowing what to think about things they didn't know were going to happen...\"\n",
    "story2= \"`` I've been having trouble sleeping this whole time ''   `` You know what happens when you wake up without getting used to it! Like always with your dreams or even if they weren't real... But that was never my intention at all but as an old man who still loves her every night so much for being there everyday because she can't sleep anymore isnt going away any more then anything ever before.. It just happened too soon though - after about twenty years ago i went back home from work thinking how bad we were today since our childhood together on Christmas Eve morning last year & not wanting anyone to notice ; luckily mom said something good like 10 minutes till midnight tonight.. So do me some coffee now lol haha ) The first thing I noticed immediately afterwards during waking up had been my eyes staring into the ceiling while trying desperately to keep myself awake ( which caused me to fall asleep pretty quickly anyways ) And although nothing else seemed quite right until maybe another day where I woke up naked by my bedside table instead of lying down beside my head curled up next to my mattress/chair etc.. except apparently no idea why didnt someone mention it yet oh well anyway ok fine im glad people are interested enough here let me go okay bye woahaha wtf am I sure its cool alright OK Ok mike dont worry guys ull be late once tomorrow will get better feel free to come see whats new reddit.com /r/writingprompts What did ya say sorry thats over 2 hours later lets talk english please tell us everything niceestofthisnow look forward to reading whatever prompt comes across post reply https://www2.redditimg.net/share/5E9YFg3D7h4CjMxLcQVkA1dXnRzqPJfZmU8bIwTHWt6yBiOuSvGp0NKlOWo_vuZZzz' ) Well thanks god damnit OP @ r/WritingPrompts For other stories visit [ EU ] ( http: //en.wikipedia._org//wiki/_WritingPrompts ) This subreddit has several different subreddits devoted entirely solely towards writing prompts based off of Reddit posts written exclusively on /\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I was in charge of protecting your country from the Dark Side, but I had to do it because my life depended on me not knowing what to think about things they didn't know were going to happen...\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "# Tokenize the text into sentences\n",
    "sentences = sent_tokenize(story)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(calculate_self_bleu(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-BLEU score 1: 0.9426469781691708\n",
      "Self-BLEU score 2: 0.9874474642014096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example text \n",
    "#PROMPT: Generate a Story about love.\n",
    "#gpt3.5\n",
    "file_path1 = \"/Users/Vas/Documents/Coding_Projects/BA_Experiment_Tests/Metrics/sample1.txt\"\n",
    "#gpt4\n",
    "file_path2 = \"/Users/Vas/Documents/Coding_Projects/BA_Experiment_Tests/Metrics/sample2.txt\"\n",
    "\n",
    "with open(file_path1, 'r', encoding=\"utf-8\") as file:\n",
    "    text1 = file.read()\n",
    "with open(file_path2, 'r', encoding=\"utf-8\") as file:\n",
    "    text2 = file.read()\n",
    "\n",
    "generated_text1 = text1.split('.')\n",
    "generated_text2 = text2.split('.')\n",
    "self_bleu_score1 = calculate_self_bleu(generated_text1)\n",
    "self_bleu_score2 = calculate_self_bleu(generated_text2)\n",
    "print(f'Self-BLEU score 1: {1-self_bleu_score1}')\n",
    "print(f'Self-BLEU score 2: {1-self_bleu_score2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
