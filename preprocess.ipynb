{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. limit story length to 1000 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the length of eac story from all raw datasets to 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"train\", \"test\", \"valid\"]\n",
    "for name in data:\n",
    "    with open(\"data/hd/raw/\" + name + \".wp_target\") as f:\n",
    "        stories = f.readlines()\n",
    "    stories = [\" \".join(i.split()[0:1000]) for i in stories]\n",
    "    with open(\"data/hd/prepro/\" + name + \".wp_target\", \"w\") as o:\n",
    "        for line in stories:\n",
    "            o.write(line.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean texts from unwanted artifacts and Combine each prompt with its corresponding story to a new txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define regex pattern for impurities\n",
    "pattern = r\"(<newline>)|(newline)|\\(Edit\\s*:\\s*[^\\)]*\\)|[^a-zA-Z\\s.]|'\\s+(?=\\.)'|'(?i)\\s*\\bif you like(d)? this\\s*((story|stories))?[^.]*\\.?'\"\n",
    "pattern2 = r\"\\s+\\.\"\n",
    "\n",
    "names = [\"train\", \"test\", \"valid\"]\n",
    "\n",
    "for name in names:\n",
    "    # Python script to concatenate prompts and stories\n",
    "    with open('data/hd/prepro/' + name + '.wp_source', 'r', encoding='utf-8') as sources, \\\n",
    "         open('data/hd/prepro/' + name + '.wp_target', 'r', encoding='utf-8') as targets, \\\n",
    "         open('data/hd/initial_combined/' + name + '_combined.txt', 'w', encoding='utf-8') as outfile:\n",
    "        for prompt, story in zip(sources, targets):\n",
    "            cleaned_prompt = re.sub(r\"\\<[^\\>]*\\>|\\[ WP \\]|\\-\\-\", \"\", prompt[6:])\n",
    "            cleaned_prompt = re.sub(pattern, \"\", cleaned_prompt)\n",
    "            cleaned_prompt = re.sub(pattern2, \".\", cleaned_prompt)\n",
    "            cleaned_prompt = re.sub(r'\\s{2,}', ' ', cleaned_prompt)\n",
    "            cleaned_story = re.sub(pattern, \"\", story)\n",
    "            cleaned_story = re.sub(pattern2, \".\", cleaned_story)\n",
    "            cleaned_story = re.sub(r'\\s{2,}', ' ', cleaned_story)\n",
    "            outfile.write(cleaned_prompt.strip() + \"\\n\" + cleaned_story.strip() + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We partition our human-generated data (from train_combined.txt) into decreasing portions for each subsequent generation, ensuring that each generation sees a unique subset of the human data for the first time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate Split Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries per file: [109040, 81780, 61335, 46001, 34500, 25875, 19406, 14555, 10916]\n"
     ]
    }
   ],
   "source": [
    "def count_entries(filepath):\n",
    "    \"\"\"Counts the number of double-newline-separated entries in a file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read().strip()\n",
    "    return len(content.split('\\n\\n'))\n",
    "\n",
    "def calculate_portions(total_entries, initial_portion=0.40):\n",
    "    \"\"\"Calculate the number of entries for each dataset based on reducing portions.\"\"\"\n",
    "    portions = [initial_portion]\n",
    "    current_portion = initial_portion\n",
    "\n",
    "    # Assuming a reduction of 25% relatively per generation\n",
    "    while current_portion > 0.05:  # Continue until the portion is very small\n",
    "        current_portion *= 0.75\n",
    "        portions.append(current_portion)\n",
    "\n",
    "    # Calculate the number of entries per portion\n",
    "    entries_per_portion = [int(total_entries * p) for p in portions]\n",
    "    return entries_per_portion\n",
    "\n",
    "# Example usage\n",
    "total_entries = count_entries('./data/hd/initial_combined/train_combined.txt')\n",
    "entries_distribution = calculate_portions(total_entries)\n",
    "print(\"Entries per file:\", entries_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(filepath, portions):\n",
    "    import random\n",
    "    \n",
    "    # Read the entire file and split by entries\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read().strip().split('\\n\\n')\n",
    "    \n",
    "    random.shuffle(content)  # Shuffle to randomize the entries distribution\n",
    "\n",
    "    # Calculate the starting index for each portion\n",
    "    total_len = len(content)\n",
    "    portions_indices = [0]\n",
    "    cumulative_sum = 0\n",
    "\n",
    "    for portion in portions:\n",
    "        cumulative_sum += int(total_len * portion)\n",
    "        portions_indices.append(cumulative_sum)\n",
    "\n",
    "    # Write out each portion to a different file\n",
    "    for i in range(len(portions_indices) - 1):\n",
    "        with open(f'data/hd/combined{i}/train_combined{i}.txt', 'w', encoding='utf-8') as f:\n",
    "            for entry in content[portions_indices[i]:portions_indices[i+1]]:\n",
    "                f.write(entry + \"\\n\\n\")\n",
    "\n",
    "# Example usage\n",
    "portions = [0.40, 0.30, 0.20, 0.10]  # Adjust based on total data and requirements\n",
    "split_data('./data/hd/initial_combined/train_combined.txt', portions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109040\n",
      "81780\n",
      "54520\n",
      "27260\n"
     ]
    }
   ],
   "source": [
    "print(count_entries('./data/hd/combined0/train_combined0.txt'))\n",
    "print(count_entries('./data/hd/combined1/train_combined1.txt'))\n",
    "print(count_entries('./data/hd/combined2/train_combined2.txt'))\n",
    "print(count_entries('./data/hd/combined3/train_combined3.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that there is no data leakage between the different train_combined#.txt files we want to verify that each dataset is unique and that entries from one dataset do not appear in another.\n",
    "1. Hash Checking\n",
    "calculate a unique hash for each entry in every dataset and ensure that no hash appears in more than one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined0/train_combined0.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined1/train_combined1.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined2/train_combined2.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined2/train_combined2.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined1/train_combined1.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Leakage detected! Entry in ./data/hd/combined3/train_combined3.txt already appears in ./data/hd/combined0/train_combined0.txt\n",
      "Total Leakages: 111\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def compute_hash(text):\n",
    "    \"\"\"Computes an MD5 hash for the given text.\"\"\"\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "def check_leakage(files):\n",
    "    seen_hashes = {}\n",
    "    leakage = False\n",
    "    leakage_count = 0\n",
    "\n",
    "    for filename in files:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            content = file.read().strip()\n",
    "        entries = content.split('\\n\\n')\n",
    "\n",
    "        for entry in entries:\n",
    "            entry_hash = compute_hash(entry)\n",
    "            if entry_hash in seen_hashes:\n",
    "                leakage_count += 1\n",
    "                print(f\"Leakage detected! Entry in {filename} already appears in {seen_hashes[entry_hash]}\")\n",
    "                #print(entry)\n",
    "                #break\n",
    "                leakage = True\n",
    "            else:\n",
    "                seen_hashes[entry_hash] = filename\n",
    "\n",
    "    if not leakage:\n",
    "        print(\"No data leakage detected among the files.\")\n",
    "    \n",
    "    print(\"Total Leakages:\",leakage_count)\n",
    "\n",
    "# List your files\n",
    "files = ['./data/hd/combined0/train_combined0.txt', './data/hd/combined1/train_combined1.txt', \n",
    "         './data/hd/combined2/train_combined2.txt', './data/hd/combined3/train_combined3.txt']\n",
    "check_leakage(files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
