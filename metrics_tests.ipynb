{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def calculate_distinct_n(text, n=2):\n",
    "    \"\"\"\n",
    "    Calculate the Distinct-n metric for a given text. This metric evaluates the diversity of generated text \n",
    "    by counting the number of unique sequences of n words (n-grams).\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to be analyzed.\n",
    "    - n (int): The length of the n-gram (e.g., 2 for Distinct-2).\n",
    "\n",
    "    Returns:\n",
    "    - float: The Distinct-n score as the proportion of unique n-grams to the total number of n-grams.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove special characters and normalize to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    # Split the cleaned text into tokens\n",
    "    tokens = cleaned_text.split()\n",
    "    #print(tokens)\n",
    "    # Generate n-grams from the list of tokens\n",
    "    n_grams = [' '.join(tokens[i:i + n]) for i in range(len(tokens) - n + 1)]\n",
    "    #print(len(n_grams))\n",
    "    # Calculate the number of unique n-grams\n",
    "    unique_n_grams = len(set(n_grams))\n",
    "    #print(len(set(n_grams)))\n",
    "    # Calculate the total number of n-grams\n",
    "    total_n_grams = len(n_grams)\n",
    "    \n",
    "    # Calculate the Distinct-n score\n",
    "    distinct_n_score =  unique_n_grams/total_n_grams if total_n_grams > 0 else 0\n",
    "    print(distinct_n_score)\n",
    "    return distinct_n_score\n",
    "    #return total_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911764705882353\n",
      "0.9974619289340102\n",
      "0.9855595667870036\n",
      "0.9911894273127754\n",
      "0.9901234567901235\n",
      "0.8992628992628993\n",
      "0.9906976744186047\n",
      "0.9942363112391931\n",
      "0.9906759906759907\n",
      "1.0\n",
      "0.9975728155339806\n",
      "1.0\n",
      "0.9975247524752475\n",
      "0.9970760233918129\n",
      "0.9945945945945946\n",
      "0.9950980392156863\n",
      "1.0\n",
      "0.990632318501171\n",
      "1.0\n",
      "0.9883720930232558\n",
      "0.9792207792207792\n",
      "0.9894459102902374\n",
      "0.9811764705882353\n",
      "0.9973474801061007\n",
      "0.9950124688279302\n",
      "0.981859410430839\n",
      "0.9941348973607038\n",
      "0.9973614775725593\n",
      "0.9949748743718593\n",
      "0.9775561097256857\n",
      "1.0\n",
      "0.9943820224719101\n",
      "0.9893238434163701\n",
      "0.9550561797752809\n",
      "0.9928057553956835\n",
      "0.9975786924939467\n",
      "1.0\n",
      "0.9901477832512315\n",
      "0.9975247524752475\n",
      "0.9903381642512077\n",
      "0.9952830188679245\n",
      "0.9886039886039886\n",
      "0.9901960784313726\n",
      "0.9817708333333334\n",
      "0.9943019943019943\n",
      "0.9710526315789474\n",
      "0.9966777408637874\n",
      "0.992\n",
      "0.9847715736040609\n",
      "0.9937888198757764\n",
      "0.9947089947089947\n",
      "0.989821882951654\n",
      "1.0\n",
      "0.96\n",
      "0.9971751412429378\n",
      "1.0\n",
      "0.9915014164305949\n",
      "0.9929577464788732\n",
      "1.0\n",
      "0.9851485148514851\n",
      "0.9437939110070258\n",
      "0.9291784702549575\n",
      "0.9528535980148883\n",
      "0.9852216748768473\n",
      "1.0\n",
      "0.9905660377358491\n",
      "0.9823232323232324\n",
      "1.0\n",
      "0.9974093264248705\n",
      "0.9902676399026764\n",
      "0.99\n",
      "0.9897959183673469\n",
      "0.9930394431554525\n",
      "0.9829268292682927\n",
      "0.9948849104859335\n",
      "0.9914772727272727\n",
      "1.0\n",
      "0.9959016393442623\n",
      "0.9894179894179894\n",
      "0.9942857142857143\n",
      "0.9949109414758269\n",
      "0.9942857142857143\n",
      "0.9918918918918919\n",
      "0.997289972899729\n",
      "0.995049504950495\n",
      "1.0\n",
      "0.9927007299270073\n",
      "0.9904988123515439\n",
      "0.9865951742627346\n",
      "1.0\n",
      "0.9744186046511628\n",
      "0.9818181818181818\n",
      "0.9976019184652278\n",
      "0.9948320413436692\n",
      "1.0\n",
      "0.9948717948717949\n",
      "0.9946236559139785\n",
      "0.9823788546255506\n",
      "0.9974937343358395\n",
      "0.9974226804123711\n",
      "Data has been written to ./outputs/gen5/eval_table_gen5.csv\n",
      "Average values for each metric:\n",
      "Distinct-2    0.989383\n",
      "Name: Average, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7468/368113324.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_eval = pd.concat([df_eval, new_row_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#from metrics.LexicalDiversity.lexical_diversity import *\n",
    "#from metrics.SemanticDiversity.sementic_diversity import *\n",
    "#from metrics.SyntacticDiversity.syntactic_diversity import *\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "#import spacy\n",
    "\n",
    "# Define the column names\n",
    "#columns = [\"Distinct-2\", \"Distinct-3\", \"Self-BLEU\", \"OV-TTR\", \"MS-TTR\", \"S-DIV-AV\", \"S-DIV-C\", \"SYN-DIV\"]\n",
    "columns = [\"Distinct-2\"]\n",
    "\n",
    "# Create an empty DataFrame with these columns\n",
    "df_eval = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Load a spaCy model for dependency parsing\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"./outputs/gen7/stories7.txt\", 'r') as f:\n",
    "#with open(\"data/hd/initial_combined/test_combined.txt\") as f:\n",
    "    stories = f.read().split(\"\\n\\n\")\n",
    "#stories = '\\n\\n'.join(stories)\n",
    "\n",
    "for story in stories:\n",
    "    #print(stories.index(story))\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    #sentences = sent_tokenize(story)\n",
    "    #graphs = construct_dependency_graphs(sentences)\n",
    "\n",
    "    #A new row of data\n",
    "    new_data = {\n",
    "        \"Distinct-2\": calculate_distinct_n(story, 2),\n",
    "        #\"Distinct-3\": calculate_distinct_n(story, 3),\n",
    "        #\"Self-BLEU\": 1-calculate_self_bleu(sentences),\n",
    "        #\"OV-TTR\": calculate_ttr(story, truncate_length=300),\n",
    "        #\"MS-TTR\": calculate_mean_segmental_ttr(story, segment_size=50),\n",
    "        #\"S-DIV-AV\": calculate_semantic_diversity(sentences, 'average'),\n",
    "        #\"S-DIV-C\": calculate_semantic_diversity(sentences, 'centroid'),\n",
    "        #\"SYN-DIV\": calculate_syntactic_diversity(graphs)\n",
    "    }\n",
    "\n",
    "    # Convert new_data dictionary to a DataFrame\n",
    "    new_row_df = pd.DataFrame([new_data])\n",
    "\n",
    "    # Concatenate the new row DataFrame to the original DataFrame\n",
    "    df_eval = pd.concat([df_eval, new_row_df], ignore_index=True)\n",
    "        \n",
    "\n",
    "# Calculate the mean for each column and append as a new row\n",
    "averages = df_eval.mean().to_dict()\n",
    "averages = {key: [value] for key, value in averages.items()}  # Convert each mean value into a list\n",
    "average_df = pd.DataFrame(averages)  # Create a DataFrame for the averages\n",
    "average_df.index = ['Average']  # Label the index as 'Average'\n",
    "\n",
    "# Append the average row to the original DataFrame\n",
    "df = pd.concat([df_eval, average_df])\n",
    "\n",
    "# Specify the file path and name\n",
    "file_path = './outputs/gen5/eval_table_gen5.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#df.to_csv(file_path, index=False)  # Set index=False to not include row indices in the file\n",
    "\n",
    "print(f\"Data has been written to {file_path}\")\n",
    "# Print the last row (average values)\n",
    "print(\"Average values for each metric:\")\n",
    "print(df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
