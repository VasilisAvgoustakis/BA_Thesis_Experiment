{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Traning Data for GEN1 Training \n",
    "We create a new txt file \"data/md/combined1/train1_combined.txt\" about the same size as the original training file \"data/hd/prepro/combined0/train_combined.txt\" \n",
    "of which 3/4 or 75% is randomly picked from the original text file and 1/4 or 25% is randomly picked from the file containing the synthetic data from GEN0, \"data/sd/gen0/gen0_sd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully combined and written to train1_combined.txt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    return data\n",
    "\n",
    "def write_data(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n\\n'.join(data))\n",
    "\n",
    "# Load data\n",
    "original_data = read_data('./data/hd/prepro/combined0/train_combined.txt')\n",
    "synthetic_data = read_data('./data/sd/gen0/gen0_sd.txt')\n",
    "\n",
    "# Determine portions\n",
    "three_quarters_len = int(0.75 * len(original_data))\n",
    "one_quarter_len = int(0.25 * len(original_data))\n",
    "\n",
    "# Randomly sample data\n",
    "selected_original = random.sample(original_data, three_quarters_len)\n",
    "selected_synthetic = random.sample(synthetic_data, one_quarter_len)\n",
    "\n",
    "# Combine and shuffle\n",
    "combined_data = selected_original + selected_synthetic\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Write combined data to a new file\n",
    "write_data(combined_data, './data/md/combined1/train1_combined.txt')\n",
    "print(\"Data has been successfully combined and written to train1_combined.txt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional think it is more correct to keep the same validation set so that we can also compare the different gens performance metrics.)\n",
    "We follow the same logic to create a hybrid validation dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully combined and written to train1_combined.txt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Load data\n",
    "original_data = read_data('./data/hd/prepro/combined0/valid_combined.txt')\n",
    "synthetic_data = read_data('./data/sd/gen0/gen0_sd.txt')\n",
    "\n",
    "# Determine portions\n",
    "three_quarters_len = int(0.75 * len(original_data))\n",
    "one_quarter_len = int(0.25 * len(original_data))\n",
    "\n",
    "# Randomly sample data\n",
    "selected_original = random.sample(original_data, three_quarters_len)\n",
    "selected_synthetic = random.sample(synthetic_data, one_quarter_len)\n",
    "\n",
    "# Combine and shuffle\n",
    "combined_data = selected_original + selected_synthetic\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Write combined data to a new file\n",
    "write_data(combined_data, './data/md/combined1/valid1_combined.txt')\n",
    "print(\"Data has been successfully combined and written to train1_combined.txt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning\n",
    "### Step 2\n",
    "\n",
    "Finetune the model GEN1 for 5 epochs with the combined txt file containing 3/4th real data and 1/4 synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepspeed run_clm.py \\\n",
    "    --model_name_or_path distilgpt2 \\\n",
    "    --train_file data/md/prepro/combined1/train1_combined.txt \\\n",
    "    --validation_file data/hd/prepro/combined0/valid_combined.txt \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --output_dir ./models/distilgpt2-finetuned_gen1 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --save_strategy epoch \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --deepspeed ds_config.json \\\n",
    "    --resume_from_checkpoint ./models/distilgpt2-finetuned_gen0/checkpoint-27765\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
